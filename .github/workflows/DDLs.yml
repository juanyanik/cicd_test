name: Snowflake DDL Extraction

on:
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight
  workflow_dispatch:  # Allow manual trigger

jobs:
  extract-snowflake-ddls:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install snowflake-connector-python
    
    - name: Extract Snowflake DDLs
      env:
        SF_ACCOUNT: ${{ secrets.SF_ACCOUNT }}
        SF_USERNAME: ${{ secrets.SF_USERNAME }}
        SF_PASSWORD: ${{ secrets.SF_PASSWORD }}
        SF_ROLE: ${{ secrets.SF_ROLE }}
        SF_WAREHOUSE: ${{ secrets.SF_WAREHOUSE }}
        SF_DATABASE: ${{ secrets.SF_DATABASE }}
      run: |
        cat << 'EOF' > extract_ddls.py
        import snowflake.connector
        import os
        import json

        # Ensure base directory exists
        base_dir = 'snowflake_ddls'
        os.makedirs(base_dir, exist_ok=True)

        # Create a marker file to ensure the directory is tracked even if empty
        with open(os.path.join(base_dir, '.gitkeep'), 'w') as f:
            f.write('')

        def quote_identifier(identifier):
            return f'"{identifier}"'

        # Snowflake connection
        conn = snowflake.connector.connect(
            account=os.environ['SF_ACCOUNT'],
            user=os.environ['SF_USERNAME'],
            password=os.environ['SF_PASSWORD'],
            role=os.environ['SF_ROLE'],
            warehouse=os.environ['SF_WAREHOUSE'],
            database=os.environ['SF_DATABASE']
        )

        cursor = conn.cursor()

        # Function to create directory and save DDL
        def save_ddl(object_type, schema, name, ddl):
            # Create directory structure
            dir_path = f'{base_dir}/{object_type}/{schema}'
            os.makedirs(dir_path, exist_ok=True)
            
            # Save DDL to file
            file_path = f'{dir_path}/{name}.sql'
            with open(file_path, 'w') as f:
                f.write(ddl)
            print(f"Saved DDL to {file_path}")

        # Get current database
        current_db = os.environ['SF_DATABASE']
        print(f"Processing database: {current_db}")

        # First, use the database
        cursor.execute(f"USE DATABASE {quote_identifier(current_db)}")

        try:
            # Extract schemas
            cursor.execute(f"SHOW SCHEMAS IN DATABASE {quote_identifier(current_db)}")
            schemas = [row[1] for row in cursor.fetchall() 
                      if not row[1].startswith('INFORMATION_SCHEMA') 
                      and row[1] not in ['ACCOUNT_USAGE', 'SNOWFLAKE']]
            print(f"Found schemas: {schemas}")

            for schema in schemas:
                print(f"Processing schema: {schema}")
                quoted_schema = quote_identifier(schema)
                
                # Use the schema
                cursor.execute(f"USE SCHEMA {quoted_schema}")
                
                try:
                    # Tables
                    cursor.execute(f"SHOW TABLES IN SCHEMA {quote_identifier(current_db)}.{quoted_schema}")
                    tables = cursor.fetchall()
                    print(f"Found {len(tables)} tables in {schema}")
                    
                    for table in tables:
                        table_name = table[1]
                        quoted_table = quote_identifier(table_name)
                        print(f"Extracting DDL for table: {table_name}")
                        cursor.execute(f"SELECT GET_DDL('TABLE', '{quote_identifier(current_db)}.{quoted_schema}.{quoted_table}')")
                        ddl = cursor.fetchone()[0]
                        save_ddl('tables', schema, table_name, ddl)
                    
                    # Views
                    cursor.execute(f"SHOW VIEWS IN SCHEMA {quote_identifier(current_db)}.{quoted_schema}")
                    views = cursor.fetchall()
                    print(f"Found {len(views)} views in {schema}")
                    
                    for view in views:
                        view_name = view[1]
                        quoted_view = quote_identifier(view_name)
                        print(f"Extracting DDL for view: {view_name}")
                        cursor.execute(f"SELECT GET_DDL('VIEW', '{quote_identifier(current_db)}.{quoted_schema}.{quoted_view}')")
                        ddl = cursor.fetchone()[0]
                        save_ddl('views', schema, view_name, ddl)
                    
                    # Stored Procedures
                    cursor.execute(f"SHOW PROCEDURES IN SCHEMA {quote_identifier(current_db)}.{quoted_schema}")
                    procs = cursor.fetchall()
                    print(f"Found {len(procs)} procedures in {schema}")
                    
                    for proc in procs:
                        proc_name = proc[1]
                        quoted_proc = quote_identifier(proc_name)
                        print(f"Extracting DDL for procedure: {proc_name}")
                        cursor.execute(f"SELECT GET_DDL('PROCEDURE', '{quote_identifier(current_db)}.{quoted_schema}.{quoted_proc}')")
                        ddl = cursor.fetchone()[0]
                        save_ddl('procedures', schema, proc_name, ddl)
                
                except Exception as e:
                    print(f"Error processing schema {schema}: {str(e)}")
                    continue

        except Exception as e:
            print(f"Error processing database: {str(e)}")
        finally:
            conn.close()
            print("Snowflake connection closed")
        EOF
        python extract_ddls.py
    
    - name: Commit and push changes
      run: |
        git config user.name github-actions
        git config user.email github-actions@github.com
        
        # Check if there are any changes to commit
        if [ -d "snowflake_ddls" ]; then
          if git status --porcelain | grep .; then
            echo "Changes detected, committing..."
            git add snowflake_ddls/
            git commit -m "Update Snowflake DDLs"
            git push
          else
            echo "No changes to commit"
          fi
        else
          echo "snowflake_ddls directory not found"
          exit 1
        fi
